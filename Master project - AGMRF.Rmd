---
title: "Master project"
author: "Halvard"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Libraries
library(ggplot2) #plotting
library(tidyr) #for pivot_longer?
library(ggpubr)
library(INLA) #posterior inference
library(MASS) #for ginv
```

# Some theory
## Random walk 1
The easiest way to simulate a random walk is through the assumption of independent normal distributed increments. We know that '
$$
x_{t+1} | x_1, ..., x_t, \sigma = x_{t+1}|x_t, \sigma \sim N(x_t, \sigma^2)
$$
Thus, all we need to do is sample from the standard normal, scale them by $\sigma$ and add them sequentially. Standard to assert that $x_0 = 0$.


Defining a basic plotting function that will come in handy

```{r}
plot_realizations <- function(df, title, xlabel = "t", ylabel = "y", legend = TRUE){
  #Need to give in a dataframe with fitting colnames, used by the legend
  df$t <- 1:nrow(df)  # Create a time index from 1 to n
  df_long <- df %>% pivot_longer(cols = -t, names_to = "variable", values_to = "value")
  
  ggplot(df_long, aes(x = t, y = value, color = variable)) +
  geom_line() +
  labs(title = title, 
       x = xlabel, y = ylabel) +
    if (legend) {theme(legend.title = element_blank())}
    else {theme(legend.position = "none")}
}
```

Now, lets define functionality for the random walk.
```{r}
RW1 <- function(sigma, N){
  # sigma^2 is the variance for the transitions and N is the number of points
  x <- rep(0, N)
  z <- sigma * rnorm(N-1)
  for(j in 2:N){
    x[j] <- x[j-1] + z[j-1]
  }
  return(x)
}

#Also making a normalized RW1, ie. it sums to zero
Norm_RW1 <- function(sigma, N){
  # sigma^2 is the variance for the transitions and N is the number of points
  x <- rep(0, N)
  z <- sigma * rnorm(N-1)
  for(j in 2:N){
    x[j] <- x[j-1] + z[j-1]
  }
  return(x -  mean(x)) #makes the mean zero
}

#Parameters for simulation of RW1
n <- 10
N <- 100
sigma <- 1

df <- data.frame(matrix(NA, nrow = N, ncol = n))
set.seed(0)
for (i in 1:n){
  df[, i] <- RW1(sigma, N) 
}

RW1_plot <- plot_realizations(df, "RW1 with N=100", legend = FALSE)
```

## Random walk 2
$$
x_t - 2x_{t+1} + x_{t+2} \sim N(0, \sigma^2)
$$
$$
x_{t+2} \sim N(2x_{t+1} - x_t, \sigma^2)
$$
$$
x_{t+2} = 2x_{t+1} - x_t + \epsilon_t, \quad
\epsilon_t \sim N(0, \sigma^2)
$$

```{r}
RW2 <- function(sigma, N){
  # sigma^2 is the variance for the transitions and N is the number of points
  x <- rep(0, N)
  z <- sigma * rnorm(N-1)
  for(j in 3:N){
    x[j] <- 2*x[j-1] - x[j-2] + z[j-1]
  }
  return(x)
}

#Parameters for simulation of RW2
n <- 10
N <- 100
sigma <- 1

df2 <- data.frame(matrix(NA, nrow = N, ncol = n))
set.seed(0)
for (i in 1:n){
  df2[, i] <- RW2(sigma, N)
}

# Plot all lines using ggplot
RW2_plot <- plot_realizations(df2, "RW2 with N=100", legend = FALSE)
```

Visualize the plots.
```{r}
RW_figure <- ggarrange(RW1_plot, RW2_plot, ncol = 1)
RW_figure
```

###  Brief testing with INLA on some simulated data
We will fit the simple model in INLA with a latent layer as
$$
\eta_t = \mu + x_t
$$
where $x_t$ is a RW1 with some precision $\tau$ with a default prior. We use a Gaussian likelihood in the observation layer, again with a default prior for the precision. Same for $\mu$.

```{r}
#Data preperation
sim_data <- something #and a mean
test_data <- data.frame(matrix(c(sim_data, 1:N, 1:N), nrow = N, ncol = 3)) 
colnames(test_data) <- c("y", "time", "us") #makes the colnames match the formula

#The INLA model
formula <- y ~ f(time, model = "rw1") + f(us, model = "iid") #intercept is included automatically
res <- inla(formula, family = "gaussian", data = test_data)

#For plotting the data and the predicted values
plot_df <- data.frame(matrix(c(test_data[, 1], res$summary.fitted.values$mean), ncol = 2))
colnames(plot_df) <- c("sim_data", "preds") #for legends in the plot

plot_realizations(plot_df, "Simulated data and predicted values for non-shocked data")
```

We see that the model predictions align well with the data it is fit on.

## Implementing the adaptive random walk in INLA
As this is somewhat complicated and new to me, I will start by a slightly easier example, namely the RW1. Can then also compare it to the already defined RW1 in INLA to ensure it works as intended. First some basic theory on defining random effects in INLA from https://becarioprecario.bitbucket.io/inla-gitbook/ch-newmodels.html .

### Defining new latent random effects in INLA
New latent effects must be specified as GMRFs. The general structure of the inla.rgeneric is shown below:
```{r, eval=FALSE}
inla.rgeneric.somemodel = function(
  cmd = c("graph", "Q", "mu", "initial", "log.norm.const","log.prior", "quit"),
  theta = NULL)
{
  # for reference and potential storage for objects to
  # cache, this is the environment of this function
  # which holds arguments passed as `...` in
  # `inla.rgeneric.define()`.
  envir = parent.env(environment())
  graph = function(){ <to be completed> }
  Q = function() { <to be completed> }
  mu = function() { <to be completed> }
  log.norm.const = function() { <to be completed> }
  log.prior = function() { <to be completed> }
  initial = function() { <to be completed> }
  quit = function() { <to be completed> }
  
  # sometimes this is useful, as argument 'graph' and 'quit'
  # will pass theta=numeric(0) (or NULL in R-3.6...) as
  # the values of theta are NOT
  # required for defining the graph. however, this statement
  # will ensure that theta is always defined.
  
  if (!length(theta)) theta = initial()
  val = do.call(match.arg(cmd), args = list())
  return (val)
}

#if W is a needed argument
somemodel.model <- inla.rgeneric.define(inla.rgeneric.somemodel, W = W)

```

### Implementing a RW1 in INLA
In a RW1 we only have one hyperparameter, namely $\tau$. So we get $\theta = \text{log}(\tau)$ and the precision matrix was defined previously. Lets first define a function for the geometric variance, defined in the overleaf document, to scale the precision matrix. Use the function ginv from the library MASS to calculate the generalized inverse.
```{r}
geometric_variance <- function(R) {
  #Input: R is a square structure matrix, often sparse
  N <- dim(R)[1]
  GV <- exp(1 / N * sum(log(diag(ginv(R)))))
  return(GV)
}
```

Then, lets define the inla.rgeneric function with all its necessary subfunctions.
```{r}
inla.rgeneric.RW1.model = function(
  cmd = c("graph", "Q", "mu", "initial", "log.norm.const","log.prior", "quit"),
  theta = NULL)
{
  #Input:
  #N is the number of timepoints
  #R_star is the scaled structure matrix
  
  envir = parent.env(environment())
  
  interpret_theta <- function() { return(list(tau = exp(theta[1L])))}
  
  graph <- function() {return(Q())}
  
  Q <- function() {
    p <- interpret_theta()
    Q <- p$tau * R_star
    return(inla.as.sparse(Q))
  }
  
  mu <- function() {return(numeric(0))}
  
  initial <- function() {return(4)}#default for precisions: initial = 4
  
  log.norm.const <- function() {return(numeric(0))} #Inla computes it
  
  log.prior <- function() {#default: shape = 1, rate = 0.00005 for tau
    p <- interpret_theta()
    prior <- dgamma(p$tau, shape = 1, rate = 0.00005, log = TRUE) + log(p$tau)
    return(prior)
  }
  
  quit <- function() {return(invisible())}
  
  #to ensure theta is defined
  if (!length(theta)) theta = initial()
  
  vals <- do.call(match.arg(cmd), args = list())
  return(vals)
}
```

We need to pass the function above the number of timepoints $N$ and the scaled structure matrix $R^*$. The scaled structure matrix for a RW1 is defined by the fucntion below, followed by some testing.

```{r}
Q <- function(N) {
  # Input: N timepoints
  R <- toeplitz(c(2, -1, rep(0, N - 2)))# 2 on diag and -1 on firstdiags
  R[1, 1] <- R[N, N] <- 1 # 1 for first and last diag element
  gv <- geometric_variance(R)
  R_star <- gv * R 
  return(R_star) #returns the scaled structure matrix for a RW1
}

N <- 50 #is defined further up as well
R_star <- Q(N) 
RW1_model <- inla.rgeneric.define(inla.rgeneric.RW1.model, N = N, R_star = R_star)
```

RW1 model with Q defined inside the rgeneric function instead of being passed as an argument.

Additionally, we can construct and RW1 where we construct and scale the precision matrix $Q$ inside the rgeneric functions. This is slightly slower as we needto compute $Q$ every time the model is used, but the code is more readable and requires fewer lines and arguments.

```{r}
inla.rgeneric.RW1.model2 = function(
  cmd = c("graph", "Q", "mu", "initial", "log.norm.const","log.prior", "quit"),
  theta = NULL)
{
  #Input:
  #N is the number of timepoints
  
  envir = parent.env(environment())
  
  interpret_theta <- function() {return(list(tau = exp(theta[1L])))}
  
  graph <- function() {return(Q())}
  
  Q <- function() {
    R <- toeplitz(c(2, -1, rep(0, N - 2)))# 2 on diag and -1 on firstdiags
    R[1, 1] <- R[N, N] <- 1 # 1 for first and last diag element
    gv <- exp(1 / N * sum(log(diag(INLA:::inla.ginv(R))))) #the geometric variance
    R_star <- gv * R 
    
    p <- interpret_theta()
    Q <- p$tau * R_star
    return(inla.as.sparse(Q))
  }
  
  mu <- function() {return(numeric(0))}
  
  initial <- function() {return(4)}#default for precisions: initial = 4
  
  log.norm.const <- function() {return(numeric(0))} #Inla computes it
  
  log.prior <- function() {#default: shape = 1, rate = 0.00005 for tau
    p <- interpret_theta()
    prior <- dgamma(p$tau, shape = 1, rate = 0.00005, log = TRUE) + log(p$tau)
    return(prior)
  }
  
  quit <- function() {return(invisible())}
  
  #to ensure theta is defined
  if (!length(theta)) theta = initial()
  
  vals <- do.call(match.arg(cmd), args = list())
  return(vals)
}

N <- 50 #is defined further up as well
RW1_model2 <- inla.rgeneric.define(inla.rgeneric.RW1.model2, N = N)
```

The RW1_model above is now a custom latent effect which can be included in INLA formulas to define models. However, it is only defined for $N=50$, and we need to define separate ones for other $N$. Now, lets check if it works as intended on some data from earlier. Then we need to define the INLA formula where we add a constraint to enforce a sum to zero constraint as the model includes an intercept. We also need to scale the RW1 defined by INLA by setting scale.model = T.
```{r}
exp_func <- function(x){
  return(exp(x))
}
set.seed(15)
t <- 1:N
y <- sin(t/N*2) + rnorm(N, sd = 0.2)
test_data <- as.data.frame(list(y = y, time = t, us = 1:N))

N <- 50 #is defined further up as well
RW1_model2 <- inla.rgeneric.define(inla.rgeneric.RW1.model2, N = N)

#The INLA formula for a latent model with intercept and user defined RW1
formula_M <- y ~ f(time, model = RW1_model2, 
                extraconstr = list(A = matrix(1, nrow = 1, ncol = N), e = 0)) +
  f(us, model = "iid")
res_M <- inla(formula_M, family = "gaussian", data = test_data)

#The standard RW1 model from INLA
formula_I <- y ~ f(time, model = "rw1", scale.model = T) + f(us, model = "iid")
res_I <- inla(formula_I, family = "gaussian", data = test_data)

summary(res_M)
summary(res_I)

inla.qmarginal(c(0.025, 0.5, 0.975), inla.tmarginal(exp_func, res_M$marginals.hyperpar$`Theta1 for time`))

#plots to compare the model output
mean_plot <- ggplot() +
  geom_point(aes(x = res_M$summary.fitted.values$mean, 
                 y = res_I$summary.fitted.values$mean)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "blue") +
  labs(title = "Comparison of the Mean", x = "Manual RW1", y = "INLA's RW1") +
  theme_minimal()
sd_plot <- ggplot() +
  geom_point(aes(x = res_M$summary.fitted.values$sd, 
                 y = res_I$summary.fitted.values$sd)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "blue") +
  labs(title = "Comparison of the standard deviation", x = "Manual RW1", y = "INLA's RW1") +
  theme_minimal()

comp_plot <- ggarrange(mean_plot, sd_plot, ncol = 2)

#ggsave("C:/Users/Halvard/Documents/GitHub/Master-project/RW1_comparison_fig.pdf", comp_plot, width = 8, height = 4, units = "in")
```
From the summaries it is clear they are very similar. However, not exactly equal, as for instance the mean of the Gaussian precision. This is supported by the plots of the means and standard deviations, which show that they are almost the same, but clearly not identical. We also note that the run-time for the manual model is much longer than the one implemented by INLA, so I will use INLA's predefined model from here on out for better computational times.

### Implementing the adaptive RW1
We now make the previous model more flexible by allowing for two different precisions in the random walk. The new precision is used for transitions involving conflict years which we define. So, we start by computing the scaled structure matrices R1_star and R2_star which we need as inputs for the adaptive random walk.

```{r}
Scaled_structure_matrices_for_ARW1 <- function(N, conflict_years) {
  #Input:
  #N timepoints
  #conflict_years is a list with the conflict years
  
  R1 <- matrix(0, nrow = N, ncol = N) #should be N = 50, non-conflict
  R2 <- matrix(0, nrow = N, ncol = N) #should be N = 50, conflict
  for( i in 1:(N - 1)){
    if(i %in% conflict_years | (i + 1) %in% conflict_years) {
      R2[c(i, i+1), c(i, i+1)] <- R2[c(i, i+1), c(i, i+1)] + c(1, -1, -1, 1)
    }
    else {
      R1[c(i, i+1), c(i, i+1)] <- R1[c(i, i+1), c(i, i+1)] + c(1, -1, -1, 1)
    }
  }
  gv <- geometric_variance(R1 + R2) #scaling
  return(list(R1 = R1*gv, R2 = R2*gv))
}

#testing
R_star_list <- Scaled_structure_matrices_for_ARW1(7, c(3, 4, 5))
R_star_list$R1
R <- R_star_list$R1 + R_star_list$R2
R
```

Now, lets define the adaptive RW1.
```{r}
inla.rgeneric.AdaptiveRW1.model = function(
  cmd = c("graph", "Q", "mu", "initial", "log.norm.const","log.prior", "quit"),
  theta = NULL)
{
  #Input:
  #N is the number of timepoints
  #R_star_list contains R1_star and R2_star, the scaled structure matrices
  #prior_str is either Gamma0.005, Gamma0.00005 or PC
  
  envir = parent.env(environment())
  
  interpret_theta <- function() { return(list(tau1 = exp(theta[1L]), 
                                              tau2 = exp(theta[2L])))}
  
  graph <- function() {return(Q())}
  
  Q <- function() {
    p <- interpret_theta()
    Q <- R_star_list$R1 * p$tau1 + R_star_list$R2 * p$tau2
    return(inla.as.sparse(Q)) #sparse representation
  }
  
  mu <- function() {return(numeric(0))}
  
  initial <- function() {return(c(4, 4))}#Default initial for precisions is 4
  
  log.norm.const <- function() {return(numeric(0))}
  
  log.prior <- function() {#default: shape = 1, rate = 0.00005
    p <- interpret_theta()
    if(prior_str == "PC"){
      prior <- inla.pc.dprec(p$tau1, u = 1, alpha = 0.01, log=TRUE) + log(p$tau1)+
          inla.pc.dprec(p$tau2, u = 1, alpha = 0.01, log = TRUE) + log(p$tau2)
      return(prior)
    } else if(prior_str == "Gamma0,005"){
      prior <- dgamma(p$tau1, shape = 1, rate = 0.005, log = TRUE) + log(p$tau1) +
      dgamma(p$tau2, shape = 1, rate = 0.005, log = TRUE) + log(p$tau2)
      return(prior)
    }
    prior <- dgamma(p$tau1, shape = 1, rate = 0.00005, log = TRUE) + log(p$tau1) +
    dgamma(p$tau2, shape = 1, rate = 0.00005, log = TRUE) + log(p$tau2)
    return(prior) 
  }
  
  quit <- function() {return(invisible())}
  
  #to ensure theta is defined
  if (!length(theta)) theta = initial()
  
  vals <- do.call(match.arg(cmd), args = list())
  return(vals)
}

#Computing the scaled R's and defining the ARW1 model
N <- 50 #is defined further up as well
conf_years <- 20:30 #as in the generated data further up
R_star_list <- Scaled_structure_matrices_for_ARW1(N, conf_years)
ARW1_model <- inla.rgeneric.define(inla.rgeneric.AdaptiveRW1.model, 
                                  N = N, R_star_list = R_star_list)
```

Again, the ARW1 model with Q defined inside the function.
```{r}
inla.rgeneric.AdaptiveRW1.model2 = function(
  cmd = c("graph", "Q", "mu", "initial", "log.norm.const","log.prior", "quit"),
  theta = NULL)
{
  #Input:
  #N is the number of timepoints
  #conflict_years
  #prior_str is either Gamma0.005, Gamma0.00005 or PC
  
  envir = parent.env(environment())
  
  interpret_theta <- function() { return(list(tau1 = exp(theta[1L]), 
                                              tau2 = exp(theta[2L])))}
  
  graph <- function() {return(Q())}
  
  Q <- function() {
    R1 <- matrix(0, nrow = N, ncol = N) #non-conflict
    R2 <- matrix(0, nrow = N, ncol = N) #conflict
    for( i in 1:(N - 1)){
      if(i %in% conflict_years | (i + 1) %in% conflict_years) {
        R2[c(i, i+1), c(i, i+1)] <- R2[c(i, i+1), c(i, i+1)] + c(1, -1, -1, 1)
      }
      else {
        R1[c(i, i+1), c(i, i+1)] <- R1[c(i, i+1), c(i, i+1)] + c(1, -1, -1, 1)
      }
    }
    gv <- exp(1 / N * sum(log(diag(INLA:::inla.ginv(R1 + R2))))) #scaling constant
    R_star_list <- list(R1 = R1*gv, R2 = R2*gv)
    
    p <- interpret_theta()
    Q <- R_star_list$R1 * p$tau1 + R_star_list$R2 * p$tau2
    return(inla.as.sparse(Q)) #sparse representation
  }
  
  mu <- function() {return(numeric(0))}
  
  initial <- function() {return(c(4, 4))}#Default initial for precisions is 4
  
  log.norm.const <- function() {return(numeric(0))}
  
  log.prior <- function() {#default: shape = 1, rate = 0.00005
    p <- interpret_theta()
    if(prior_str == "PC"){
      prior <- inla.pc.dprec(p$tau1, u = 1, alpha = 0.01, log=TRUE) + log(p$tau1) +
          inla.pc.dprec(p$tau2, u = 1, alpha = 0.01, log = TRUE) + log(p$tau2)
      return(prior)
    } else if(prior_str == "Gamma0,005"){
      prior <- dgamma(p$tau1, shape = 1, rate = 0.005, log = TRUE) + log(p$tau1) +
      dgamma(p$tau2, shape = 1, rate = 0.005, log = TRUE) + log(p$tau2)
      return(prior)
    }
    prior <- dgamma(p$tau1, shape = 1, rate = 0.00005, log = TRUE) + log(p$tau1) +
    dgamma(p$tau2, shape = 1, rate = 0.00005, log = TRUE) + log(p$tau2)
    return(prior) 
  }
  
  quit <- function() {return(invisible())}
  
  #to ensure theta is defined
  if (!length(theta)) theta = initial()
  
  vals <- do.call(match.arg(cmd), args = list())
  return(vals)
}
```

## Model evaluation

### Model criteria
We will evaluate the models with root mean square error (RMSE) and average proper logarithmic scoring (LS).

#### Root mean square eroor
A common model criteria is the RMSE. We define a function to calculate this below. The lower RMSE the better.

```{r}
RMSE <- function(data, preds){
  return(sqrt( sum((data - preds)**2) / length(data))) #definition of RMSE
}
```
#### Average proper logarithmic scoring rule
From a paper by Gneiting and Raftery (2007). 
$$
\text{LS}(p, \omega) = \text{log}p(\omega)
$$
where $p$ is the predicted distribution of a point, which we get from INLA, and $\omega$ is the observed value, which is the specific datapoint. We then take the average of the score for all the data points. The higher average proper LS the better.

# Recreating the simulations study by Wakefield and Aleshin-Guendel
Their simulation study compares a standard RW1 with an adaptive RW1 with an extra precision parameter for some timepoints where we expect a shock. They look at three different means in the latent layer, namely flat, delta and triangle. The latent layer is $\eta_i = \mu_i + b_i$ where $b_i \sim N(0, \tau_i^{-1})$ for some precision $\tau_i$. The observation layer is then $y_i | \eta_i \sim N(\eta_i, V)$ for some variance $V$.They choose $V$ to be $1/75$, $1/150$ or $1/300$. $\tau_i$ is either $20$ for all points or $10$ for the conflict points, which are $9-15$ out of the $N=30$ timepoints. They then combine and evaluate the model in all these cases. Lets start my creating and plotting the means in the latent layers.

```{r}
#parameters
N <- 30 #number of timepoints
n <- 100 #number of simulations in each case
conf_years <- c(9, 10, 11, 12, 13, 14, 15) #the conflict years

#defining the means
mean_flat <- rep(2, N)
mean_delta <- mean_flat + c(rep(0, 8), rep(1, 7), rep(0, 15))
mean_triangle <- mean_flat + c(rep(0, 8), c(0.3, 0.6, 0.9, 1.2, 
                                            0.9, 0.6, 0.3), rep(0, 15))

#visualizing the means
df <- data.frame(matrix(c(mean_flat, mean_delta, mean_triangle, 1:N), ncol = 4, nrow = N))

plot_flat <- ggplot(df, aes(x = X4, y = X1)) + geom_line() + 
  labs(title="Flat", y="Mean", x = "") + ylim(2, 3.25)
plot_delta <- ggplot(df, aes(x = X4, y = X2)) + geom_line() +
  labs(title="Delta", x="t", y = "") + ylim(2, 3.25)
plot_triangle <- ggplot(df, aes(x = X4, y = X3)) + geom_line() + labs(title="Triangle", x = "", y = "") + ylim(2, 3.25)

ggarrange(plot_flat, plot_delta, plot_triangle, nrow = 1, ncol = 3)
```

The next step is to make functions for simulating the data, which is done below.
```{r}
#functions to simulate data as in Wakefield and Aleshin-Guendel
sim_data_Wakefield <- function(mu, V, tau1 = 20, tau2 = 20) {
  eta <- mu + c(rnorm(8, sd = sqrt(1/tau1)), rnorm(7, sd = sqrt(1/tau2)), 
                rnorm(15, sd = sqrt(1/tau1)))
  y <- rnorm(length(mu), mean = eta, sd = sqrt(V))
  return(list(y, eta)) #[[1]] gives y and [[2]] gives eta
}

sim_dataframe_Wakefield <- function(n, mu, V, tau1 = 20, tau2 = 20, seed = 64) {
  set.seed(seed)
  mean_str <- strsplit(deparse(substitute(mu)), split = "_", fixed = TRUE)[[1]][2]
  V_str <- toString(as.integer(1/V))
  if(tau1 == tau2) {
    T_str <- "CT"
  }
  else{
    T_str <- "NCT"
  }
  df_y <- data.frame(matrix(0, nrow = length(mu), ncol = n))
  df_eta <- data.frame(matrix(0, nrow = length(mu), ncol = n))
  for (i in 1:n) {
    sim_data <- sim_data_Wakefield(mu, V, tau1 = tau1, tau2 = tau2)
    df_y[, i] <- sim_data[[1]]
    df_eta[, i] <- sim_data[[2]]
  }
  df_y$t <- 1:length(mu)
  df_y$us <- 1:length(mu)
  data_W <- list(df_y, df_eta)
  save(data_W, file = paste0("C:/Users/Halvard/Documents/GitHub/Master-project/Wakefield-data/Data_W/data_W_", mean_str, "_", V_str, "_", T_str))
  return(data_W)
}
```

Now we simulate the data for the eighteen different cases with $n = 100$ realizations of each case.
```{r}
#for constant tau (CT)

# flat mean with varying V
data_w_flat_75_CT <- sim_dataframe_Wakefield(n, mean_flat, 1/75)
data_w_flat_150_CT <- sim_dataframe_Wakefield(n, mean_flat, 1/150)
data_w_flat_300_CT <- sim_dataframe_Wakefield(n, mean_flat, 1/300)

#delta mean with varying V
data_w_delta_75_CT <- sim_dataframe_Wakefield(n, mean_delta, 1/75)
data_w_delta_150_CT <- sim_dataframe_Wakefield(n, mean_delta, 1/150)
data_w_delta_300_CT <- sim_dataframe_Wakefield(n, mean_delta, 1/300)

#triangle mean with varying V
data_w_triangle_75_CT <- sim_dataframe_Wakefield(n, mean_triangle, 1/75)
data_w_triangle_150_CT <- sim_dataframe_Wakefield(n, mean_triangle, 1/150)
data_w_triangle_300_CT <- sim_dataframe_Wakefield(n, mean_triangle, 1/300)

#for non-constant tau (NCT)
 
# flat mean with varying V
data_w_flat_75_NCT <- sim_dataframe_Wakefield(n, mean_flat, 1/75, tau2 = 10)
data_w_flat_150_NCT <- sim_dataframe_Wakefield(n, mean_flat, 1/150, tau2 = 10)
data_w_flat_300_NCT <- sim_dataframe_Wakefield(n, mean_flat, 1/300, tau2 = 10)

#delta mean with varying V
data_w_delta_75_NCT <- sim_dataframe_Wakefield(n, mean_delta, 1/75, tau2 = 10)
data_w_delta_150_NCT <- sim_dataframe_Wakefield(n, mean_delta, 1/150, tau2 = 10)
data_w_delta_300_NCT <- sim_dataframe_Wakefield(n, mean_delta, 1/300, tau2 = 10)

#triangle mean with varying V
data_w_triangle_75_NCT <- sim_dataframe_Wakefield(n, mean_triangle, 1/75, tau2 = 10)
data_w_triangle_150_NCT <- sim_dataframe_Wakefield(n, mean_triangle, 1/150, tau2 = 10)
data_w_triangle_300_NCT <- sim_dataframe_Wakefield(n, mean_triangle, 1/300, tau2 = 10)
```

# Harmonious mean
Another similar situation is when the mean is a harmonious function, say some sine function, and we again impose some offset for a subset of the time values. 
```{r, eval=FALSE}
#parameters
N <- 30
n <- 30
V <- 1/1000 #observational variance
tau1 <- 20 #latent precision in the iid noise
tau2 <- 10 
o <- 1 # the offset for points 9-15

t <- 1:N
mean_sine <- sin(pi*t/15)
mean_sine_offset <- mean_sine
mean_sine_offset[9:15] <- mean_sine_offset[9:15] + o

df_mean_sine <- data.frame(matrix(c(mean_sine,  mean_sine_offset), ncol = 2))
colnames(df_mean_sine) <- c("Non-shocked", "Shocked")
plot_realizations(df_mean_sine, "Mean for shocked and non-shocked sine data")

sim_dataframe_sine <- function(n, mu, V, tau1, tau2, o, seed = 64) {
  set.seed(seed)
  df_y <- data.frame(matrix(0, nrow = length(mu), ncol = n))
  df_eta <- data.frame(matrix(0, nrow = length(mu), ncol = n))
  for (i in 1:n) {
    sim_data <- sim_data_Wakefield(mu, V, tau1 = tau1, tau2 = tau2)
    df_y[, i] <- sim_data[[1]] #gets the y-value
    df_y[9:15, i] <- df_y[9:15, i] + o #adding the offset for 9-15
    df_eta[, i] <- sim_data[[2]]
    df_eta[9:15, i] <- df_eta[9:15, i] + o
  }
  df_y$t <- 1:length(mu)
  df_y$us <- 1:length(mu)
  return(list(df_y, df_eta))
}

df_sine_S <- sim_dataframe_sine(n, mean_sine, V, tau1, tau2, o)[[1]]

df_sine_NS <- sim_dataframe_sine(n, mean_sine, V, tau1, tau2, 0)[[1]]

plot_realizations(df_sine_NS[, 1:5], "Five realisations witout shock",, legend = FALSE)
plot_realizations(df_sine_S[, 1:5], "Five realisations with shock at 9-15", legend =FALSE)
```

Making the plot for the means.
```{r}
library(grid)

data_w_harm_300_CT <- sim_dataframe_sine(100, mean_sine, 1/300, 20, 20, 0)
data_w_sHarm_300_CT <- sim_dataframe_sine(100, mean_sine, 1/300, 20, 20, 1)

#visualizing the means
df <- data.frame(matrix(c(mean_flat, data_w_flat_300_CT[[1]][, 1], mean_delta, data_w_delta_300_CT[[1]][, 2], mean_triangle, data_w_triangle_300_CT[[1]][, 3], 1:N, mean_sine, data_w_harm_300_CT[[1]][, 4], mean_sine_offset, data_w_sHarm_300_CT[[1]][, 5]), ncol = 11, nrow = N))

ymax <- max(df[, 1:6])
ymin <- min(df[, 1:6])

ymax_sine <- max(df[, 8:11])
ymin_sine <- min(df[, 8:11])

plot_flat <- ggplot(df, aes(x = X7)) + geom_line(aes(y = X1), color = "black") + geom_point(aes(y = X2), color = "red") + labs(title="Flat", y="y", x = "t") + ylim(ymin, ymax)
plot_delta <- ggplot(df, aes(x = X7)) + geom_line(aes(y = X3), color = "black") + geom_point(aes(y = X4), color = "red") +
  labs(title="Delta", x="t", y = "") + ylim(ymin, ymax)
plot_triangle <- ggplot(df, aes(x = X7)) + geom_line(aes(y = X5), color = "black") + geom_point(aes(y = X6), color = "red") + labs(title="Triangle", x = "", y = "t") + ylim(ymin, ymax)
plot_sine <- ggplot(df, aes(x = X7)) + geom_line(aes(y = X8), color = "black") + geom_point(aes(y = X9), color = "red") + labs(title="Sine", x = "t", y = "y") + ylim(ymin_sine, ymax_sine)
plot_sine_offset <- ggplot(df, aes(x = X7)) + geom_line(aes(y = X10), color = "black") + geom_point(aes(y = X11), color = "red") + labs(title="Offset sine", x = "t", y = "") + ylim(ymin_sine, ymax_sine)

mean_plot <- ggarrange(plot_flat, plot_delta, plot_triangle, plot_sine, plot_sine_offset, nrow = 2, ncol = 3)

mean_figure <- annotate_figure(mean_plot, top = textGrob("The mean structures and a realisation", gp = (gpar(fontsize = 15))))

#save the figure
#ggsave("C:/Users/Halvard/Documents/GitHub/Master-project/HMD-plots/mean_plot.pdf", plot = mean_figure, height = 8, width = 10, units = "in")
```

#Test data
```{r}
df <- data_w_flat_300_NCT[[1]]
i <- 10
eta <- data_w_flat_300_NCT[[2]][, i]
P <- 300
N <- 30
conflict_years <- c(9, 10, 11, 12, 13, 14, 15)

test_data <- df[, c(i, n + 1, n + 2)] #gets the i-th realization + time
colnames(test_data) <- c("y", "time", "us") #makes the colnames match the formula
```

## Comparing models with $mean = 0$ with and without additional sum-to-zero constaint for components

### Comparing for free and const. iid.

```{r}
ARW1_model <- inla.rgeneric.define(inla.rgeneric.AdaptiveRW1.model, 
                    N = N, R_star_list = R_star_list_W, prior_str = "Gamma0,00005")
formula_ARW1_free <- y ~ f(time, model = ARW1_model,
                extraconstr = list(A = matrix(1, nrow = 1, ncol = N), e = 0)) +
                f(us, model = "iid")

formula_ARW1_cons <- y ~ f(time, model = ARW1_model,
                extraconstr = list(A = matrix(1, nrow = 1, ncol = N), e = 0)) +
                f(us, model = "iid", extraconstr = list(A = matrix(1, nrow = 1,
                                      ncol = N), e = 0))

res_ARW1_free <- inla(formula_ARW1_free, family = "gaussian", data = test_data,
                     control.compute = list(cpo = TRUE),
                     control.family = list(hyper = list(prec = 
                                    list(initial = log(P), fixed = TRUE))))
res_ARW1_cons <- inla(formula_ARW1_cons, family = "gaussian", data = test_data,
                     control.compute = list(cpo = TRUE),
                     control.family = list(hyper = list(prec = 
                                    list(initial = log(P), fixed = TRUE))))

#plots to compare the model output
plot(res_ARW1_free$summary.fitted.values$mean, res_ARW1_cons$summary.fitted.values$mean, 
     main = "Comparison of the mean", xlab = "Cons ARW1 with free iid", ylab = "Cons ARW1 and cons iid")
abline(0, 1)
plot(res_ARW1_free$summary.fitted.values$sd, res_ARW1_cons$summary.fitted.values$sd, 
     main = "Comparison of the standard deviation", xlab = "Cons ARW1 with free iid", ylab = "Cons ARW1 and cons iid")
abline(0, 1)
```
They look completly equal, maybe iid is enforced with sum-to-zero by default, think RW1 is as well.



# Error testing in INLA - mistakes to avoid

```{r}
#some testing
df <- data_w_flat_300_NCT[[1]]
test_data <- df[, c(1, n + 1, n + 2)] #gets the i-th realization + time
colnames(test_data) <- c("y", "time", "us") #makes the colnames match the formula
P <- 75

formula_RW1 <- y ~ f(time, model = "rw1")  + f(us, model = "iid")
res_RW1 <- inla(formula_RW1, family = "gaussian", data = test_data, 
                    control.compute = list(cpo = TRUE), 
                    control.family = list(hyper = list(prec = 
                                    list(initial = log(1), fixed = TRUE))),
                scale = P)

test_function <- function(formula, df, Prec) {
  print(Prec)
  res_RW1 <- inla(formula, family = "gaussian", data = df, 
                    control.compute = list(cpo = TRUE), 
                    control.family = list(hyper = list(prec = 
                                    list(initial = log(1), fixed = TRUE))),
                scale = Prec)
  return(res_RW1)
}
res1 <- test_function(formula_RW1, test_data, 75)

test_function2 <- function(df, Prec) {
  formula_RW1_2 <- y ~ f(time, model = "rw1")  + f(us, model = "iid")
  res_RW1 <- inla(formula_RW1_2, family = "gaussian", data = df, 
                    control.compute = list(cpo = TRUE), 
                    control.family = list(hyper = list(prec = 
                                    list(initial = log(1), fixed = TRUE))),
                  scale = Prec)
  return(res_RW1)
}
res2 <- test_function2(test_data, 75)

test_function3 <- function(formula, df, Prec) {
  res_RW1 <- inla(formula, family = "gaussian", data = df, 
                    control.compute = list(cpo = TRUE), 
                    control.family = list(hyper = list(prec = 
                                    list(initial = Prec, fixed = TRUE))))
  return(res_RW1)
}
res3 <- test_function3(formula_RW1, test_data, 3)
summary(res3)
```







