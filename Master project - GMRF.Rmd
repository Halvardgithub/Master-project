---
title: "Master project"
author: "Halvard"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Simulation of a GMRF - random walks


## Random walk 1
For the random walk 1 we have a diagonal precision matrix with $2$ on the diagonal and $-1$ on the neighboring diagonals. The first and last elements on the diagonal are set to $1$, so all rows sum to $0$. $k$ is some scale constant. We also assume a zero mean, but adding a different mean is just a location shift.

```{r}
#Creating the structure matrix
n = 4
R <- diag(2, n)
R[abs(row(R) - col(R)) == 1] <- -1
R[1, 1] <- 1
R[n, n] <- 1

R

k <- 1 #A constant connected top variance
Q <- k*R
mu <- rep(0, n)
```

Eigenvalues of R:
$$
\lambda_i = 2 - 2\text{cos}(\pi (i-1)/n), \quad i = 1, ..., n
$$
Tried sampling with Algorithm 3.1, does not appear to work as expected. Maybe its missing some constraint, like the sum of $x$ equals $0$, or something with my implementation.
```{r}
# Eigenvalues
eigVecs <- eigen(Q, symmetric=TRUE) #Finds the eigenvectors

eigVals <- rep(0, n)
for(i in 2:n){
  eigVals[i] <- (2 - 2*cos(pi*(i - 1)/n))*k #Finds the eigenvalues
}

EVInv <- rev(sqrt(1/eigVals))  #Invert and square root for scaling

z <- rnorm(n-1) #Standard normal sample
y <- rep(0, n-1)
for(i in 1:(n-1)){
  y[i] <- z[i] * EVInv[i] #Computes the ys
}
x <- rep(0, n)
for(i in 1:(n-1)){
  x <- x + y[i]*eigVecs$vectors[1+i, 1:n] 
}


```

```{r}
plot(1:n, x)
```

Another approach is to mimic the algorithms from the earlier sections, however our Q is singular
```{r}
A <- eigVecs$vectors[1, 1:n]
Q_inv <- solve(Q)
det(Q)

Q_new <- Q + A%*%t(A)

L <- t(chol(Q_new)) #The lower triangle cholesky decomp.
z <- rnorm(n)
v <- solve(t(L), z)



Q_inv <- solve(Q_new)
det(Q_new)

x_adj <- x - Q_inv%*%A *solve(t(A)%*%Q_inv%*%A)*(t(A)%*%x)
```





## Basic random walk
The easiest way to simulate a random walk is through the assumption of independent normal distributed increments. We know that '
$$
x_{t+1} | x_1, ..., x_t, \sigma = x_{t+1}|x_t, \sigma \sim N(x_t, \sigma^2)
$$
Thus, all we need to do is sample from the standard normal, scale them by $\sigma$ and add them sequentially. Standard to assert that $x_0 = 0$.


```{r}
#Libraries
library(ggplot2)
library(tidyr)

library(ggpubr)
```

```{r}
RW1 <- function(sigma, T){
  # sigma^2 is the variance for the transitions and T is the number of points
  x <- rep(0, T)
  z <- sigma * rnorm(T-1)
  for(j in 2:T){
    x[j] <- x[j-1] + z[j-1]
  }
  return(x)
}

#Parameters for simulation of RW1
n <- 10
T <- 100
sigma <- 1

df <- data.frame(matrix(NA, nrow = T, ncol = n))
set.seed(0)
for (i in 1:n){
  df[, i] <- RW1(sigma, T) 
}

df$t <- 1:nrow(df)  # Create a time index from 1 to n

# Reshape the dataframe to long format
df_long <- df %>% pivot_longer(cols = starts_with("X"), names_to = "variable", values_to = "value")

# Plot all lines using ggplot
RW1_plot <- ggplot(df_long, aes(x = t, y = value, color = variable)) +
  geom_line() +
  labs(title = "RW1 with N=100", x = "Time", y = "y") +
  theme(legend.position = "none")

```


## Random walk 2


$$
x_t - 2x_{t+1} + x_{t+2} \sim N(0, \sigma^2)\\
x_{t+2} \sim N(2x_{t+1} - x_t, \sigma^2) \\
x_{t+2} = 2x_{t+1} - x_t + \epsilon_t \\
\epsilon_t \sim N(0, \sigma^2)
$$

```{r}
RW2 <- function(sigma, T){
  # sigma^2 is the variance for the transitions and T is the number of points
  x <- rep(0, T)
  z <- sigma * rnorm(T-1)
  for(j in 3:T){
    x[j] <- 2*x[j-1] - x[j-2] + z[j-1]
  }
  return(x)
}

#Parameters for simulation of RW2
n <- 10
T <- 100
sigma <- 1

df2 <- data.frame(matrix(NA, nrow = T, ncol = n))
set.seed(0)
for (i in 1:n){
  df2[, i] <- RW2(sigma, T)
}

df2$t <- 1:nrow(df2)  # Create a time index from 1 to n

# Reshape the dataframe to long format
df2_long <- df2 %>% pivot_longer(cols = starts_with("X"), names_to = "variable", values_to = "value")

# Plot all lines using ggplot
RW2_plot <- ggplot(df2_long, aes(x = t, y = value, color = variable)) +
  geom_line() +
  labs(title = "RW2 with N=100", x = "Time", y = "y") +
  theme(legend.position = "none")


```


Visualize the plots.
```{r}
RW_figure <- ggarrange(RW1_plot, RW2_plot, ncol = 1)

RW_figure
```

# Simulation study
We want to conduct a small simulation study to see if the adaptive models improve the standard models in situations with shocks.First we will start with assessing the performance on non.shocked data.

## Simulation of non-shocked data
We will simulate data with a latent temporal structured random effect as a RW1. The total Bayesian hierarchical model can be described as
$$
Y|\lambda \sim Poisson(E\lambda) \\
\text{log}\lambda_t = \mu + x_t
$$
Where $\bf{x}$ $\sim RW1(\tau)$ where we fix $E, \mu$ and $\tau$ for the simulations. When fitting models we will need to assign priors to them. 

```{r}
#Simulating non-shocked data

#Parameters
E = 10
mu = 4
sigma = 2
T = 100 #Number of time points

#A single simulation
x <- RW1(sigma, T)
rates <- E * exp(mu + x) #rates is E*lambda or E*exp(mu + x)
y <- sapply(rates, function(r) rpois(1, r)) #samples from the Poisson

plot(1:100, x)

rates
```

The code above seems to work fine, but should possibly tune some of the parameters, or maybe the plot of the ys should look insane. 






